{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK2nTvbhYWdM1E0bJ9crJZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AronBensimhon/RL_game/blob/main/Frozen_game.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa4i9xdXbfFK",
        "outputId": "eb683194-2e3e-4959-b5a3-c71a9926e39f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.26.2\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.26.2) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.26.2) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym==0.26.2) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827725 sha256=55bc4e02281a809150173bcce193f63cd4f9bb4428360f58e950eeba1ad42df0\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/77/9e/9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install gym==0.26.2\n",
        "! pip install pygame numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym==0.26.2\n",
        "!pip install numpy==1.23.5\n",
        "import os\n",
        "os.kill(os.getpid(), 9)  # ××¨×¢× ×Ÿ ××ª ×”×§×¨× ×œ (×—×•×‘×” ×œ×©×™× ×•×™ ×™×™×›× ×¡ ×œ×ª×•×§×£)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcRwO2jSiJUM",
        "outputId": "bf4314c1-8627-43c2-ef28-54d6d18e23eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym==0.26.2 in /usr/local/lib/python3.11/dist-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.26.2) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.26.2) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym==0.26.2) (0.0.8)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym.envs.toy_text.frozen_lake import FrozenLakeEnv\n",
        "from gym.envs.registration import register\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "vf3WBib-hLo_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Cell 2: ×¤×•× ×§×¦×™×” ×œ×™×¦×™×¨×ª ×œ×•×— ××§×¨××™ (×¢×“ 3 ×—×•×¨×™×, ×¢×“ 2 ×¤×¨×¡×™×)\n",
        "# ====================================================\n",
        "def generate_custom_map(size=4, num_holes=3, num_rewards=2):\n",
        "    grid = [['F'] * size for _ in range(size)]\n",
        "    grid[0][0] = 'S'\n",
        "    grid[-1][-1] = 'G'\n",
        "\n",
        "    # ×‘×—×¨ ×¢×“ `num_holes` ×§×•××•×¨×“×™× ×˜×•×ª ×œ×—×•×¨×™×, ×œ× ×‘××§×•××•×ª S ××• G\n",
        "    holes = random.sample(\n",
        "        [(i, j) for i in range(size) for j in range(size)\n",
        "         if (i, j) not in [(0, 0), (size - 1, size - 1)]],\n",
        "        k=min(num_holes, size*size-2)\n",
        "    )\n",
        "    for i, j in holes:\n",
        "        grid[i][j] = 'H'\n",
        "\n",
        "    # ×‘×—×¨ ×¢×“ `num_rewards` ×§×•××•×¨×“×™× ×˜×•×ª ×œ×¤×¨×¡×™×, ×¨×§ ×‘×ª××™× 'F'\n",
        "    rewards = random.sample(\n",
        "        [(i, j) for i in range(size) for j in range(size) if grid[i][j] == 'F'],\n",
        "        k=min(num_rewards, sum(1 for row in grid for c in row if c == 'F'))\n",
        "    )\n",
        "    for i, j in rewards:\n",
        "        grid[i][j] = 'R'\n",
        "\n",
        "    return [''.join(row) for row in grid]"
      ],
      "metadata": {
        "id": "jaR5QW0dhbKa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Cell 3: ×¨×™×©×•× ×¡×‘×™×‘×” ××•×ª×××ª ×¢× ××–×”×” ×™×™×—×•×“×™ + render_mode='ansi'\n",
        "# ====================================================\n",
        "def make_custom_env(index=0):\n",
        "    # ×™×•×¦×¨ ××¤×” ×—×“×©×”\n",
        "    custom_map = generate_custom_map(size=4, num_holes=3, num_rewards=2)\n",
        "\n",
        "    env_id = f\"CustomFrozenLake-v{index}\"\n",
        "    register(\n",
        "        id=env_id,\n",
        "        entry_point=\"gym.envs.toy_text.frozen_lake:FrozenLakeEnv\",\n",
        "        kwargs={\"desc\": custom_map, \"is_slippery\": False},\n",
        "        max_episode_steps=100,\n",
        "        reward_threshold=0.78,\n",
        "    )\n",
        "    # render_mode='ansi' ×××¤×©×¨ env.render() ×œ×”×—×–×™×¨ ××—×¨×•×–×ª ×˜×§×¡×˜\n",
        "    env = gym.make(env_id, render_mode=\"ansi\")\n",
        "    return env, custom_map"
      ],
      "metadata": {
        "id": "-bParmFnhd-Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Cell 4: Wrapper ×œ×ª×’××•×œ ××•×ª××\n",
        "# ====================================================\n",
        "class CustomRewardWrapper(gym.Wrapper):\n",
        "    def __init__(self, env, reward_positions):\n",
        "        super().__init__(env)\n",
        "        self.reward_positions = reward_positions\n",
        "        self.size = int(np.sqrt(env.observation_space.n))\n",
        "\n",
        "    def step(self, action):\n",
        "        # ×›××Ÿ ×§×•×œ×˜ ××ª ×›×œ ×”×—××™×©×” ×¢×¨×›×™× ×©××—×–×™×¨×” env.step\n",
        "        state, reward, done, truncated, info = self.env.step(action)\n",
        "        r = -1  # ×›×œ ×¦×¢×“ ×¢×•×œ×” × ×§×•×“×”\n",
        "        row, col = divmod(state, self.size)\n",
        "        if (row, col) in self.reward_positions:\n",
        "            r += 3\n",
        "        if reward == 1:  # ×”×’×¢×” ×œ×™×¢×“\n",
        "            r += 10\n",
        "        # ×”×—×–×™×¨×• info (×•×œ× inf)\n",
        "        return state, r, done, truncated, info"
      ],
      "metadata": {
        "id": "MRWTSRfuhflv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Cell 5: ×œ×•×œ××ª ××™××•×Ÿ Q-Learning + ×”×“×¤×¡×ª ×›×œ 50 ××¤×™×–×•×“×•×ª\n",
        "# ====================================================\n",
        "# Q-table\n",
        "Q = np.zeros((16, 4))\n",
        "\n",
        "# ×”×™×¤×¨Ö¾×¤×¨××˜×¨×™×\n",
        "alpha = 0.8\n",
        "gamma = 0.95\n",
        "epsilon = 0.1\n",
        "episodes = 1000\n",
        "\n",
        "success_per_50 = []\n",
        "reward_per_50 = []\n",
        "\n",
        "success_counter = 0\n",
        "reward_accumulator = 0\n",
        "\n",
        "for episode in range(1, episodes + 1):\n",
        "    # ×™×¦×™×¨×ª ×¡×‘×™×‘×ª RL ×—×“×©×” ×œ×¤×¨×§ ×”× ×•×›×—×™\n",
        "    env, custom_map = make_custom_env(index=episode)\n",
        "    reward_positions = [\n",
        "        (i, j) for i in range(4) for j in range(4) if custom_map[i][j] == 'R'\n",
        "    ]\n",
        "    env = CustomRewardWrapper(env, reward_positions)\n",
        "\n",
        "    # ××™××•×Ÿ ×¤×¨×§\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    step_count = 0\n",
        "\n",
        "    while not done:\n",
        "        # Îµ-greedy\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q[state])\n",
        "\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        Q[state, action] += alpha * (\n",
        "            reward + gamma * np.max(Q[next_state]) - Q[state, action]\n",
        "        )\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "        step_count += 1\n",
        "\n",
        "    # ×¢×“×›×•×Ÿ ××˜×¨×™×§×•×ª\n",
        "    reward_accumulator += total_reward\n",
        "    # ×”×¦×œ×—×” = ×”×’×¢×” ×œ×™×¢×“ (×¢×˜×™×¤×ª ×ª×’××•×œ ××•×¡×™×¤×” â‰¥10 ×¨×§ ×‘×”×¦×œ×—×”)\n",
        "    if reward >= 10 and done:\n",
        "        success_counter += 1\n",
        "\n",
        "    # ×›×œ 50 ×¤×¨×§×™× â€“ ×”×“×¤×¡ ×¡×™×›×•×, ××¤×” ×•-rollout\n",
        "    if episode % 50 == 0:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"ğŸ¯ Episode {episode} | Successes: {success_counter}/50 | \"\n",
        "              f\"Avg Reward: {reward_accumulator/50:.2f}\")\n",
        "        print(f\"ğŸ“˜ Last episode steps: {step_count}\\n\")\n",
        "\n",
        "        success_per_50.append(success_counter)\n",
        "        reward_per_50.append(reward_accumulator / 50)\n",
        "        success_counter = 0\n",
        "        reward_accumulator = 0\n",
        "\n",
        "        # ×”×“×¤×¡×ª ××¤×ª ×”×“×•×’××”\n",
        "        print(\"ğŸ—ºï¸ Sample map (S=start, G=goal, H=hole, R=reward):\")\n",
        "        for row in custom_map:\n",
        "            print(\" \".join(row))\n",
        "        print()\n",
        "\n",
        "        # rollout\n",
        "        print(\"ğŸ‘£ Sample rollout:\")\n",
        "        state = env.reset()[0]\n",
        "        done = False\n",
        "        step_log = []\n",
        "\n",
        "        while not done:\n",
        "            action = np.argmax(Q[state])\n",
        "            state, reward, done, _, _ = env.step(action)\n",
        "            step_log.append(env.render())\n",
        "\n",
        "        print(f\"\\nğŸ•¹ï¸ Rollout steps: {len(step_log)}\")\n",
        "        if not step_log:\n",
        "            print(\"âš ï¸ No rollout: the agent fell or ended immediately.\")\n",
        "        else:\n",
        "            for i, frame in enumerate(step_log, start=1):\n",
        "                print(f\"\\nStep {i}:\\n{frame}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQjhvFm7hhMC",
        "outputId": "f3051efe-6a2d-4cd9-b3ff-234ca1a168bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ¯ Episode 50 | Successes: 0/50 | Avg Reward: 196.22\n",
            "ğŸ“˜ Last episode steps: 2\n",
            "\n",
            "ğŸ—ºï¸ Sample map (S=start, G=goal, H=hole, R=reward):\n",
            "S F H H\n",
            "F H F F\n",
            "R F F F\n",
            "F F R G\n",
            "\n",
            "ğŸ‘£ Sample rollout:\n",
            "\n",
            "ğŸ•¹ï¸ Rollout steps: 2\n",
            "\n",
            "Step 1:\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mHH\n",
            "FHFF\n",
            "RFFF\n",
            "FFRG\n",
            "\n",
            "\n",
            "Step 2:\n",
            "  (Right)\n",
            "SF\u001b[41mH\u001b[0mH\n",
            "FHFF\n",
            "RFFF\n",
            "FFRG\n",
            "\n",
            "\n",
            "============================================================\n",
            "ğŸ¯ Episode 100 | Successes: 0/50 | Avg Reward: 807.96\n",
            "ğŸ“˜ Last episode steps: 670\n",
            "\n",
            "ğŸ—ºï¸ Sample map (S=start, G=goal, H=hole, R=reward):\n",
            "S R F H\n",
            "F F H F\n",
            "R F F F\n",
            "F H F G\n",
            "\n",
            "ğŸ‘£ Sample rollout:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Cell 6 (××•×¤×¦×™×•× ×œ×™): ×’×¨×¤×™× ×©×œ ×”×¦×œ×—×•×ª ×•×ª×’××•×œ×™×\n",
        "# ====================================================\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(50, episodes+1, 50), success_per_50, marker='o')\n",
        "plt.title(\"Successes per 50 Episodes\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.ylim(0, 50)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(50, episodes+1, 50), reward_per_50, marker='s', color='orange')\n",
        "plt.title(\"Avg Reward per 50 Episodes\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Avg Reward\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a00NMnEbhj-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}