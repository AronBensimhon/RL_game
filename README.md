# DQN RunToTheBeach Project

This project implements a Deep Q-Network (DQN) agent trained to navigate a custom FrozenLake-style grid world using Python, PyTorch, and Pygame.

## ğŸ§  Project Overview

- **Environment**: 4Ã—4 grid with:
  - ğŸŸ¢ Start tile (S)
  - ğŸ¯ Goal tile (G)
  - ğŸ’¥ Hazard tiles (matkot â€“ H)
  - ğŸŒ® Reward tiles (falafel â€“ R)
  - ğŸ–ï¸ Safe tiles (F)
- **Agent**: Learns to reach the beach (goal) while avoiding traps and collecting falafel
- **Model**: DQN with:
  - Input: 4Ã—4Ã—6 tensor (multi-channel map encoding)
  - Network: Flatten â†’ Linear(128) â†’ ReLU â†’ Linear(4)
  - Epsilon-greedy exploration, target network, replay buffer

## ğŸ“‚ Files

| File | Description |
|------|-------------|
| `dqn_map_observation.py` | Trains the agent using DQN and saves the model as `dqn_model.pt` |
| `dqn_play_pygame.py`     | Loads the trained model and visualizes the agent in Pygame |
| `assets/`                | Contains images for the tiles (runner, falafel, matkot, sea, sand) |

## ğŸš€ How to Run

### 1. Install dependencies
```bash
pip install torch pygame matplotlib 
```


### 2. Train the agent
```bash
python dqn_map_observation.py
```

This will create dqn_model.pt

### 3. Run the visualization
```bash
python dqn_play_pygame.py
```

## ğŸ® Features
- ğŸ§± Falafel gives +3 and disappears when collected

- ğŸ’¥ Matkot trap ends the episode and penalizes the agent

- ğŸ Goal tile gives +10 and ends the episode

- ğŸ” Automatic reset each episode (or after 50 steps)

- ğŸ“ˆ Total reward graph shown during training

- âœ¨ On-screen messages: "Falafel +3!", "Matkot trap!"





